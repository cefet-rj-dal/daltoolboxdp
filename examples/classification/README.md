# Classification — Examples

Examples of classification algorithms (via scikit-learn/reticulate when applicable). Each link includes a short description.

- [skcla_knn.md](skcla_knn.md) — K-Nearest Neighbors: predicts by majority vote among the k nearest neighbors.
- [skcla_nb.md](skcla_nb.md) — Naive Bayes: applies Bayes’ rule with a conditional independence assumption among features.
- [skcla_svc.md](skcla_svc.md) — SVM (Support Vector Machine): maximizes margin; kernels enable nonlinear decision boundaries.
- [skcla_rf.md](skcla_rf.md) — Random Forest: ensemble of decision trees with majority voting; robust via bagging and feature randomness.
- [skcla_gb.md](skcla_gb.md) — Gradient Boosting: additive ensemble of trees fit to gradients of the loss.
- [skcla_mlp.md](skcla_mlp.md) — MLP (feedforward neural network): learns nonlinear decision boundaries via backpropagation.
