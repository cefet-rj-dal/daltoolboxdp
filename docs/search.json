[{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 dal authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Eduardo Ogasawara. Author, thesis advisor, maintainer. Diego Salles. Author. Eduardo Bezerra. Contributor. Federal Center Technological Education Rio de Janeiro (CEFET/RJ). Copyright holder.           CEFET/RJ","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ogasawara E, Salles D (2025). daltoolboxdp: Python-Based Extensions Data Analytics Workflows. R package version 1.1.717, https://cefet-rj-dal.github.io/daltoolboxdp/.","code":"@Manual{,   title = {daltoolboxdp: Python-Based Extensions for Data Analytics Workflows},   author = {Eduardo Ogasawara and Diego Salles},   year = {2025},   note = {R package version 1.1.717},   url = {https://cefet-rj-dal.github.io/daltoolboxdp/}, }"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/index.html","id":"id_-python-based-extensions-for-data-analytics-workflows","dir":"","previous_headings":"","what":"Python-Based Extensions for Data Analytics Workflows","title":"Python-Based Extensions for Data Analytics Workflows","text":"Python-Based Extensions Data Analytics Workflows provides Python-based extensions enhance data analytics workflows, particularly tasks involving data preprocessing predictive modeling. includes tools : Data sampling transformation Feature selection Balancing strategies (e.g., SMOTE) Model construction tuning capabilities leverage Python libraries via reticulate interface, enabling seamless integration broader Python machine learning ecosystem. package supports instance selection hybrid workflows combine R Python functionalities flexible reproducible analytical pipelines. architecture inspired Experiment Lines approach, promotes modularity, extensibility, interoperability across tools. information Experiment Lines available Ogasawara et al. (2009).","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Python-Based Extensions for Data Analytics Workflows","text":"can install latest stable version CRAN: install development version GitHub:","code":"install.packages(\"daltoolboxdp\") # install.packages(\"devtools\") library(devtools) devtools::install_github(\"cefet-rj-dal/daltoolboxdp\", force = TRUE, dependencies = FALSE, upgrade = \"never\")"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Python-Based Extensions for Data Analytics Workflows","text":"Example scripts available : daltoolboxdp/examples","code":"library(daltoolboxdp) #> Registered S3 method overwritten by 'quantmod': #>   method            from #>   as.zoo.data.frame zoo #> Registered S3 methods overwritten by 'forecast': #>   method  from  #>   head.ts stats #>   tail.ts stats  # Example usage (replace with actual function when available) # e.g., data <- my_sampler_function(data, method = \"undersample\")"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/index.html","id":"bug-reports-and-feature-requests","dir":"","previous_headings":"","what":"Bug reports and feature requests","title":"Python-Based Extensions for Data Analytics Workflows","text":"Please report issues suggest new features via: GitHub Issues","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/bal_oversampling.html","id":null,"dir":"Reference","previous_headings":"","what":"Oversampling — bal_oversampling","title":"Oversampling — bal_oversampling","text":"Oversampling balances class distribution dataset increasing representation minority class dataset. wraps smotefamily library.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/bal_oversampling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Oversampling — bal_oversampling","text":"","code":"bal_oversampling(attribute)"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/bal_oversampling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Oversampling — bal_oversampling","text":"attribute class attribute target balancing using oversampling.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/bal_oversampling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Oversampling — bal_oversampling","text":"bal_oversampling object.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/bal_oversampling.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Oversampling — bal_oversampling","text":"","code":"data(iris) mod_iris <- iris[c(1:50,51:71,101:111),]  bal <- bal_oversampling('Species') bal <- daltoolbox::fit(bal, mod_iris) adjust_iris <- daltoolbox::transform(bal, mod_iris) table(adjust_iris$Species) #>  #>     setosa versicolor  virginica  #>         50         42         44"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/bal_subsampling.html","id":null,"dir":"Reference","previous_headings":"","what":"Subsampling — bal_subsampling","title":"Subsampling — bal_subsampling","text":"Subsampling balances class distribution dataset reducing representation majority class dataset.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/bal_subsampling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subsampling — bal_subsampling","text":"","code":"bal_subsampling(attribute)"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/bal_subsampling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subsampling — bal_subsampling","text":"attribute class attribute target balancing using subsampling","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/bal_subsampling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subsampling — bal_subsampling","text":"bal_subsampling object.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/bal_subsampling.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Subsampling — bal_subsampling","text":"","code":"data(iris) mod_iris <- iris[c(1:50,51:71,101:111),]  bal <- bal_subsampling('Species') bal <- daltoolbox::fit(bal, mod_iris) adjust_iris <- daltoolbox::transform(bal, mod_iris) table(adjust_iris$Species) #>  #>     setosa versicolor  virginica  #>         11         11         11"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/cla_gb.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient Boosting Classifier — cla_gb","title":"Gradient Boosting Classifier — cla_gb","text":"Implements classifier using Gradient Boosting algorithm. function wraps GradientBoostingClassifier Python's scikit-learn library.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/cla_gb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient Boosting Classifier — cla_gb","text":"","code":"cla_gb(   attribute,   slevels,   loss = \"log_loss\",   learning_rate = 0.1,   n_estimators = 100,   subsample = 1,   criterion = \"friedman_mse\",   min_samples_split = 2,   min_samples_leaf = 1,   min_weight_fraction_leaf = 0,   max_depth = 3,   min_impurity_decrease = 0,   init = NULL,   random_state = NULL,   max_features = NULL,   verbose = 0,   max_leaf_nodes = NULL,   warm_start = FALSE,   validation_fraction = 0.1,   n_iter_no_change = NULL,   tol = 1e-04,   ccp_alpha = 0 )"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/cla_gb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient Boosting Classifier — cla_gb","text":"attribute Target attribute name model building slevels Possible values target classification loss Loss function optimized ('log_loss', 'exponential') learning_rate Learning rate shrinks contribution tree n_estimators Number boosting stages perform subsample Fraction samples used fitting individual base learners criterion Function measure quality split min_samples_split Minimum number samples required split internal node min_samples_leaf Minimum number samples required leaf node min_weight_fraction_leaf Minimum weighted fraction sum total weights max_depth Maximum depth individual regression estimators min_impurity_decrease Minimum impurity decrease required split init Estimator object initialize model random_state Random number generator seed max_features Number features consider best split verbose Controls verbosity output max_leaf_nodes Maximum number leaf nodes warm_start Whether reuse solution previous call validation_fraction Proportion training data set aside validation n_iter_no_change Used decide early stopping used tol Tolerance early stopping ccp_alpha Complexity parameter cost-complexity pruning","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/cla_gb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient Boosting Classifier — cla_gb","text":"Gradient Boosting classifier object cla_gb object","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/cla_gb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gradient Boosting Classifier — cla_gb","text":"Tree Boosting","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/cla_gb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient Boosting Classifier — cla_gb","text":"","code":"library(daltoolboxdp)"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs.html","id":null,"dir":"Reference","previous_headings":"","what":"Feature Selection — fs","title":"Feature Selection — fs","text":"Feature selection process selecting subset relevant features larger set features dataset use model training. FeatureSelection class R provides framework performing feature selection.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature Selection — fs","text":"","code":"fs(attribute)"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature Selection — fs","text":"attribute target variable.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Feature Selection — fs","text":"instance FeatureSelection class.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Feature Selection — fs","text":"","code":"#See ?fs_fss for an example of feature selection"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_fss.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward Stepwise Selection — fs_fss","title":"Forward Stepwise Selection — fs_fss","text":"Forward stepwise selection technique feature selection attributes added model one time based ability improve model's performance. stops adding candidate addition significantly improve model adjustment. wraps leaps library.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_fss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward Stepwise Selection — fs_fss","text":"","code":"fs_fss(attribute)"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_fss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward Stepwise Selection — fs_fss","text":"attribute target variable.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_fss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward Stepwise Selection — fs_fss","text":"fs_fss object.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_fss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward Stepwise Selection — fs_fss","text":"","code":"data(iris) myfeature <- daltoolbox::fit(fs_fss(\"Species\"), iris) data <- daltoolbox::transform(myfeature, iris) head(data) #>   Sepal.Length Petal.Length Petal.Width Species #> 1          5.1          1.4         0.2  setosa #> 2          4.9          1.4         0.2  setosa #> 3          4.7          1.3         0.2  setosa #> 4          4.6          1.5         0.2  setosa #> 5          5.0          1.4         0.2  setosa #> 6          5.4          1.7         0.4  setosa"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_ig.html","id":null,"dir":"Reference","previous_headings":"","what":"Information Gain — fs_ig","title":"Information Gain — fs_ig","text":"Information Gain feature selection technique based information theory. measures information obtained target variable knowing presence absence feature. wraps FSelector library.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_ig.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Information Gain — fs_ig","text":"","code":"fs_ig(attribute)"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_ig.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Information Gain — fs_ig","text":"attribute target variable.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_ig.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Information Gain — fs_ig","text":"fs_ig object.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_ig.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Information Gain — fs_ig","text":"","code":"data(iris) myfeature <- daltoolbox::fit(fs_ig(\"Species\"), iris) data <- daltoolbox::transform(myfeature, iris) head(data) #>   Petal.Width Petal.Length Species #> 1         0.2          1.4  setosa #> 2         0.2          1.4  setosa #> 3         0.2          1.3  setosa #> 4         0.2          1.5  setosa #> 5         0.2          1.4  setosa #> 6         0.4          1.7  setosa"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_lasso.html","id":null,"dir":"Reference","previous_headings":"","what":"Feature Selection using Lasso — fs_lasso","title":"Feature Selection using Lasso — fs_lasso","text":"Feature selection using Lasso regression technique selecting subset relevant features. wraps glmnet library.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_lasso.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature Selection using Lasso — fs_lasso","text":"","code":"fs_lasso(attribute)"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_lasso.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature Selection using Lasso — fs_lasso","text":"attribute target variable.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_lasso.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Feature Selection using Lasso — fs_lasso","text":"fs_lasso object.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_lasso.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Feature Selection using Lasso — fs_lasso","text":"","code":"data(iris) myfeature <- daltoolbox::fit(fs_lasso(\"Species\"), iris) data <- daltoolbox::transform(myfeature, iris) head(data) #>   Sepal.Width Petal.Length Petal.Width Species #> 1         3.5          1.4         0.2  setosa #> 2         3.0          1.4         0.2  setosa #> 3         3.2          1.3         0.2  setosa #> 4         3.1          1.5         0.2  setosa #> 5         3.6          1.4         0.2  setosa #> 6         3.9          1.7         0.4  setosa"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_relief.html","id":null,"dir":"Reference","previous_headings":"","what":"Relief — fs_relief","title":"Relief — fs_relief","text":"Feature selection using Relief technique selecting subset relevant features. calculates relevance feature considering difference feature values nearest neighbors different classes. wraps FSelector library.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_relief.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relief — fs_relief","text":"","code":"fs_relief(attribute)"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_relief.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relief — fs_relief","text":"attribute target variable.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_relief.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Relief — fs_relief","text":"fs_relief object.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/fs_relief.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Relief — fs_relief","text":"","code":"data(iris) myfeature <- daltoolbox::fit(fs_relief(\"Species\"), iris) data <- daltoolbox::transform(myfeature, iris) head(data) #>   Petal.Width Petal.Length Species #> 1         0.2          1.4  setosa #> 2         0.2          1.4  setosa #> 3         0.2          1.3  setosa #> 4         0.2          1.5  setosa #> 5         0.2          1.4  setosa #> 6         0.4          1.7  setosa"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_gb.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient Boosting Classifier — skcla_gb","title":"Gradient Boosting Classifier — skcla_gb","text":"Implements classifier using Gradient Boosting algorithm. function wraps GradientBoostingClassifier Python's scikit-learn library.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_gb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient Boosting Classifier — skcla_gb","text":"","code":"skcla_gb(   attribute,   slevels,   loss = \"log_loss\",   learning_rate = 0.1,   n_estimators = 100,   subsample = 1,   criterion = \"friedman_mse\",   min_samples_split = 2,   min_samples_leaf = 1,   min_weight_fraction_leaf = 0,   max_depth = 3,   min_impurity_decrease = 0,   init = NULL,   random_state = NULL,   max_features = NULL,   verbose = 0,   max_leaf_nodes = NULL,   warm_start = FALSE,   validation_fraction = 0.1,   n_iter_no_change = NULL,   tol = 1e-04,   ccp_alpha = 0 )"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_gb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient Boosting Classifier — skcla_gb","text":"attribute Target attribute name model building slevels Possible values target classification loss Loss function optimized ('log_loss', 'exponential') learning_rate Learning rate shrinks contribution tree n_estimators Number boosting stages perform subsample Fraction samples used fitting individual base learners criterion Function measure quality split min_samples_split Minimum number samples required split internal node min_samples_leaf Minimum number samples required leaf node min_weight_fraction_leaf Minimum weighted fraction sum total weights max_depth Maximum depth individual regression estimators min_impurity_decrease Minimum impurity decrease required split init Estimator object initialize model random_state Random number generator seed max_features Number features consider best split verbose Controls verbosity output max_leaf_nodes Maximum number leaf nodes warm_start Whether reuse solution previous call validation_fraction Proportion training data set aside validation n_iter_no_change Used decide early stopping used tol Tolerance early stopping ccp_alpha Complexity parameter cost-complexity pruning","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_gb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient Boosting Classifier — skcla_gb","text":"Gradient Boosting classifier object skcla_gb object","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_gb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gradient Boosting Classifier — skcla_gb","text":"Tree Boosting","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_gb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient Boosting Classifier — skcla_gb","text":"","code":"#See an example of using `skcla_gb` at this #https://github.com/cefet-rj-dal/daltoolboxdp/blob/main/examples/skcla_gb.md"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_knn.html","id":null,"dir":"Reference","previous_headings":"","what":"K-Nearest Neighbors Classifier — skcla_knn","title":"K-Nearest Neighbors Classifier — skcla_knn","text":"Implements classification using K-Nearest Neighbors algorithm. function wraps KNeighborsClassifier Python's scikit-learn library.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_knn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"K-Nearest Neighbors Classifier — skcla_knn","text":"","code":"skcla_knn(   attribute,   slevels,   n_neighbors = 5,   weights = \"uniform\",   algorithm = \"auto\",   leaf_size = 30,   p = 2,   metric = \"minkowski\",   metric_params = NULL,   n_jobs = NULL )"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_knn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"K-Nearest Neighbors Classifier — skcla_knn","text":"attribute Target attribute name model building slevels List possible values classification target n_neighbors Number neighbors use queries weights Weight function used prediction ('uniform', 'distance') algorithm Algorithm used compute nearest neighbors ('auto', 'ball_tree', 'kd_tree', 'brute') leaf_size Leaf size passed BallTree KDTree p Power parameter Minkowski metric metric Distance metric tree ('euclidean', 'manhattan', 'chebyshev', 'minkowski', etc.) metric_params Additional parameters metric function n_jobs Number parallel jobs neighbor searches","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_knn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"K-Nearest Neighbors Classifier — skcla_knn","text":"K-Nearest Neighbors classifier object skcla_knn object","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_knn.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"K-Nearest Neighbors Classifier — skcla_knn","text":"K-Nearest Neighbors Classifier","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_knn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"K-Nearest Neighbors Classifier — skcla_knn","text":"","code":"#See an example of using `skcla_knn` at this #https://github.com/cefet-rj-dal/daltoolboxdp/blob/main/examples/skcla_knn.md"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_mlp.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi-layer Perceptron Classifier — skcla_mlp","title":"Multi-layer Perceptron Classifier — skcla_mlp","text":"Implements classification using Multi-layer Perceptron algorithm. function wraps MLPClassifier Python's scikit-learn library.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_mlp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi-layer Perceptron Classifier — skcla_mlp","text":"","code":"skcla_mlp(   attribute,   slevels,   hidden_layer_sizes = c(100),   activation = \"relu\",   solver = \"adam\",   alpha = 1e-04,   batch_size = \"auto\",   learning_rate = \"constant\",   learning_rate_init = 0.001,   power_t = 0.5,   max_iter = 200,   shuffle = TRUE,   random_state = NULL,   tol = 1e-04,   verbose = FALSE,   warm_start = FALSE,   momentum = 0.9,   nesterovs_momentum = TRUE,   early_stopping = FALSE,   validation_fraction = 0.1,   beta_1 = 0.9,   beta_2 = 0.999,   epsilon = 1e-08,   n_iter_no_change = 10,   max_fun = 15000 )"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_mlp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multi-layer Perceptron Classifier — skcla_mlp","text":"attribute Target attribute name model building slevels List possible values classification target hidden_layer_sizes Number neurons hidden layer activation Activation function hidden layer ('identity', 'logistic', 'tanh', 'relu') solver solver weight optimization ('lbfgs', 'sgd', 'adam') alpha L2 penalty (regularization term) parameter batch_size Size minibatches stochastic optimizers learning_rate Learning rate schedule weight updates learning_rate_init Initial learning rate used power_t Exponent inverse scaling learning rate max_iter Maximum number iterations shuffle Whether shuffle samples iteration random_state Seed random number generation tol Tolerance optimization verbose Whether print progress messages stdout warm_start Whether reuse previous solution momentum Momentum gradient descent update nesterovs_momentum Whether use Nesterov's momentum early_stopping Whether use early stopping validation_fraction Proportion training data validation beta_1 Exponential decay rate estimates first moment vector beta_2 Exponential decay rate estimates second moment vector epsilon Value numerical stability adam n_iter_no_change Maximum number epochs meet tol improvement max_fun Maximum number loss function calls","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_mlp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multi-layer Perceptron Classifier — skcla_mlp","text":"Multi-layer Perceptron classifier object skcla_mlp object","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_mlp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multi-layer Perceptron Classifier — skcla_mlp","text":"Neural Network Classifier","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_mlp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multi-layer Perceptron Classifier — skcla_mlp","text":"","code":"#See an example of using `skcla_mlp` at this #https://github.com/cefet-rj-dal/daltoolboxdp/blob/main/examples/skcla_mlp.md"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_nb.html","id":null,"dir":"Reference","previous_headings":"","what":"Gaussian Naive Bayes Classifier — skcla_nb","title":"Gaussian Naive Bayes Classifier — skcla_nb","text":"Implements classification using Gaussian Naive Bayes algorithm. function wraps GaussianNB Python's scikit-learn library.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_nb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gaussian Naive Bayes Classifier — skcla_nb","text":"","code":"skcla_nb(attribute, slevels, var_smoothing = 1e-09, priors = NULL)"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_nb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gaussian Naive Bayes Classifier — skcla_nb","text":"attribute Target attribute name model building slevels List possible values classification target var_smoothing Portion largest variance features added variances priors Prior probabilities classes. specified must list length n_classes","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_nb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gaussian Naive Bayes Classifier — skcla_nb","text":"Naive Bayes classifier object skcla_nb object","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_nb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gaussian Naive Bayes Classifier — skcla_nb","text":"Naive Bayes Classifier","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_nb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gaussian Naive Bayes Classifier — skcla_nb","text":"","code":"#See an example of using `skcla_nb` at this #https://github.com/cefet-rj-dal/daltoolboxdp/blob/main/examples/skcla_nb.md"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_rf.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Forest Classifier — skcla_rf","title":"Random Forest Classifier — skcla_rf","text":"Implements classification using Random Forest algorithm. function wraps RandomForestClassifier Python's scikit-learn library.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_rf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Forest Classifier — skcla_rf","text":"","code":"skcla_rf(   attribute,   slevels,   n_estimators = 100,   criterion = \"gini\",   max_depth = NULL,   min_samples_split = 2,   min_samples_leaf = 1,   min_weight_fraction_leaf = 0,   max_features = \"sqrt\",   max_leaf_nodes = NULL,   min_impurity_decrease = 0,   bootstrap = TRUE,   oob_score = FALSE,   n_jobs = NULL,   random_state = NULL,   verbose = 0,   warm_start = FALSE,   class_weight = NULL,   ccp_alpha = 0,   max_samples = NULL,   monotonic_cst = NULL )"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_rf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Forest Classifier — skcla_rf","text":"attribute Target attribute name model building slevels List possible values classification target n_estimators Number trees random forest criterion Function name measuring split quality max_depth Maximum tree depth value min_samples_split Minimum samples needed internal node split min_samples_leaf Minimum samples needed leaf node min_weight_fraction_leaf Minimum weighted fraction value max_features Number features consider best split max_leaf_nodes Maximum number leaf nodes min_impurity_decrease Minimum impurity decrease needed split bootstrap Whether use bootstrap samples oob_score Whether use --bag samples n_jobs Number parallel jobs random_state Seed random number generation verbose Whether enable verbose output warm_start Whether reuse previous solution class_weight Weights associated classes ccp_alpha Complexity parameter value pruning max_samples Number samples training estimators monotonic_cst Monotonicity constraints features","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_rf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random Forest Classifier — skcla_rf","text":"Random Forest classifier object skcla_rf object","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_rf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random Forest Classifier — skcla_rf","text":"Tree Ensemble","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_rf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random Forest Classifier — skcla_rf","text":"","code":"#See an example of using `skcla_rf` at this #https://github.com/cefet-rj-dal/daltoolboxdp/blob/main/examples/skcla_rf.md"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_svc.html","id":null,"dir":"Reference","previous_headings":"","what":"Support Vector Machine Classification — skcla_svc","title":"Support Vector Machine Classification — skcla_svc","text":"Implements classification using Support Vector Machine (SVM) algorithm. function wraps SVC classifier Python's scikit-learn library.","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_svc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Support Vector Machine Classification — skcla_svc","text":"","code":"skcla_svc(   attribute,   slevels,   kernel = \"rbf\",   degree = 3,   gamma = \"scale\",   coef0 = 0,   tol = 0.001,   C = 1,   shrinking = TRUE,   probability = FALSE,   cache_size = 200,   class_weight = NULL,   verbose = FALSE,   max_iter = -1,   decision_function_shape = \"ovr\",   break_ties = FALSE,   random_state = NULL )"},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_svc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Support Vector Machine Classification — skcla_svc","text":"attribute Target attribute name model building slevels List possible values classification target kernel Kernel function type ('linear', 'poly', 'rbf', 'sigmoid') degree Polynomial degree using 'poly' kernel gamma Kernel coefficient value coef0 Independent term value kernel function tol Tolerance value stopping criterion C Regularization strength parameter shrinking Whether use shrinking heuristic probability Whether enable probability estimates cache_size Kernel cache size value MB class_weight Weights associated classes verbose Whether enable verbose output max_iter Maximum number iterations decision_function_shape Shape decision function ('ovo', 'ovr') break_ties Whether break tie decisions random_state Seed random number generation","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_svc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Support Vector Machine Classification — skcla_svc","text":"SVM classifier object skcla_svc object","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_svc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Support Vector Machine Classification — skcla_svc","text":"SVM Classifier","code":""},{"path":"https://cefet-rj-dal.github.io/daltoolboxdp/reference/skcla_svc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Support Vector Machine Classification — skcla_svc","text":"","code":"#See an example of using `skcla_svc` at this #https://github.com/cefet-rj-dal/daltoolboxdp/blob/main/examples/cla_svm.md"}]
