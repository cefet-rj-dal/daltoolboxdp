## Feature Selection with Information Gain (IG)

This example shows how to use the Information Gain method to rank attributes and select a relevant subset for the target. Then, we apply the transformation to keep only the chosen attributes along with the target.

Prerequisites
- R packages: daltoolbox, daltoolboxdp

```{r}
# Installation (if needed)
#install.packages("daltoolboxdp")
```

```{r}
# Loading packages
library(daltoolbox)
library(daltoolboxdp)
```


```{r}
# Example data
iris <- datasets::iris
```

```{r}
# Information Gain (IG) - step by step

# 1) Fit the feature selector (target: Species)
myfeature <- fit(fs_ig("Species"), iris)

# 2) View selected features
print(myfeature$features)

# 3) Apply transformation to keep only selected features + target
data <- transform(myfeature, iris)
print(head(data))
```

### Method

Information Gain measures the reduction in class label entropy achieved by splitting on a feature. Features that yield larger entropy reduction are considered more informative for predicting the target.

### References
- Quinlan, J. R. (1993). C4.5: Programs for Machine Learning. Morgan Kaufmann.

