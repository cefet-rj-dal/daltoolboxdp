## Feature Selection with Lasso

Lasso performs linear modeling with an L1 penalty on coefficients, which drives some coefficients exactly to zero. This induces sparsity and acts as embedded feature selection by retaining only the most predictive features under the penalized objective.

This example uses Lasso (L1 regularization) to select relevant features based on their relationship to the target variable. L1 induces sparsity in coefficients, removing less important features.

Prerequisites
- R packages: daltoolbox, daltoolboxdp

```{r}
# Installation (if needed)
#install.packages("daltoolboxdp")
```

```{r}
# Loading packages
library(daltoolbox)
library(daltoolboxdp)
```


```{r}
# Example data
iris <- datasets::iris
```

```{r}
# Lasso - step by step

# 1) Fit the selector with target "Species"
myfeature <- fit(fs_lasso("Species"), iris)

# 2) View selected features
print(myfeature$features)

# 3) Transform data to keep selected features + target
data <- transform(myfeature, iris)
print(head(data))
```

References
- Tibshirani, R. (1996). Regression Shrinkage and Selection via the Lasso. Journal of the Royal Statistical Society: Series B, 58(1), 267â€“288.

